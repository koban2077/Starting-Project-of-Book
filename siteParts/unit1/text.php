<div class="text">
When we think of computers (if ever) we tend to think they have always been around. For most people under the age of thirty, they have been in one form or another…from laptops to iPhones. The road to the latest <span class="nontech_translate" >gadget</span>, however, has taken over a hundred years and the work of many people.<br><br>

                In computer science, we identify <span class="people_translate">Blaise Pascal</span>  (1622-1663), a French mathematician, as the first in a line of people who made the computers we have today possible. Although the people of China and Japan, at the time, used an <span class="nontech_translate">abacus</span> to do calculations, those in Europe still relied on the pen and paper method. <img src="img/unit_1/pascaline.jpg" alt="pascaline" class="image_pascaline">Pascal invented the <span class="people_translate">Pascaline</span> that allowed people to do addition and subtraction mechanically by turning dials (see Fig. 1).  The Pascaline was further <span class="nontech_translate">enhanced</span> by the German mathematician, Gottfried von Leibnitz, by making it able to do multiplication and division.


                <br><img src="img/unit_1/1.jpg" alt="1" class="pic1"><br>
                <span class="people_translate">Joseph Marie Jacquard</span> (1752-1834) was a French <span class="nontech_translate">weaver</span> trying to come up with a way to make silk cloth with patterns without mistakes. At the time (early 1800s), everything was done by hand and errors were frequently made, making the cloth useless. Based on previous work by other French weavers, Jacquard developed the “Jacquard loom”. The Jacquard Loom is a mechanical loom that uses cards with <span class="tech_translate">punched holes</span> , each card corresponding to one row of the design. The concept was later used for the first punched-card computers in the 1950s and 1960s.
<span class="tech_translate"></span>
                <br><br>
                Two of the most <span class="nontech_translate">prominent</span> names in the history of computing are <span class="people_translate">Charles Babbage</span> (1791-1891) and <span class="people_translate">Lady Ada Lovelace</span> (1815-1852).

                <br><img src="img/unit_1/2.jpg" alt="2" class="pic2"><br>
                <span class="people_translate">Babbage</span> was an English mathematician, philosopher, inventor and mechanical engineer. He came up with the concept of a <span class="tech_translate">digital</span> programmable computer. He is considered by many to be <span class="people_translate">"The Father of the Computer"</span> . He invented first mechanical computer that eventually led to more complex electronic designs -  all the essential ideas of modern computers are to be found in Babbage's <span class="nontech_translate">analytical engine</span> .

                <br><img src="img/unit_1/3.jpg" alt="3" class="pic3"><br>


                <span class="people_translate">Lovelace</span>, the only <span class="nontech_translate">legitimate</span> child of the English poet Byron, was an English mathematician and writer. She was the first to recognize that Babbage’s analytical engine had applications beyond pure calculation. She created the first <span class="tech_translate">algorithm</span> intended to be carried out by such a machine. Because of that, she is often regarded as the <span class="people_translate">first computer programmer</span>. The US Department of Defense named Ada, a multipurpose programming language, after her in recognition of her contributions to the field of computing.

                <br><br><br><br>
                <div class="fact"> <span class="bold">FACTOID:</span>  The Science Museum in London constructed a working difference engine No. 2 from 1989 to 1991 to celebrate the 200th anniversary of Babbage's birth. In 2000, the printer which Babbage originally designed for the difference engine was also completed. Both worked <span class="nontech_translate">flawlessly</span>.</div>
                <br>
                <br><img src="img/unit_1/turing.jpg" alt="turing" class="turing">
                <br>

                <span class="people_translate">Alan Turing</span> (1912–1954) was an English computer scientist, mathematician, <span class="tech_translate">logician</span>, <span class="tech_translate">cryptanalyst</span>, philosopher and theoretical biologist.<br><br>

                He was highly influential in the development of theoretical computer science, providing a formal structure of the concepts of algorithms and computation with the Turing machine. It is considered a model of a general-purpose computer. <span class="people_translate">Turing</span> is considered <span class="people_translate">"The Father of Theoretical Computer Science and Artificial Intelligence"</span> .<br><br>

                During the World War II, he worked for the British codebreaking center that produced Ultra intelligence. Turing played a pivotal role in <span class="tech_translate">cracking</span>  <span class="tech_translate">intercepted</span> coded messages that enabled the Allies to defeat the Nazis in many crucial engagements.<br><br>

                In 1950, he developed the <span class="people_translate">Turing test</span> which tested a machine's ability to <span class="nontech_translate">exhibit</span> intelligent behavior <span class="nontech_translate">equivalent</span> to, or <span class="nontech_translate">indistinguishable</span> from, that of a human. Since Turing first introduced his test, it has proven to be both highly influential and widely criticized, and it has become an important concept in the philosophy of artificial intelligence.
                <br><img src="img/unit_1/neumann.jpg" alt="neuman" class="neuman">  <br>


                <span class="people_translate">John von Neumann</span> (1903– 1957) was a Hungarian-American mathematician, physicist, inventor, computer scientist, and <span class="tech_translate">polymath</span>. He made major contributions to many fields, including mathematics, physics, economics (<span class="tech_translate">game theory</span>), computing (<span class="people_translate">Von Neumann architecture</span>, linear programming, <span class="tech_translate">self-replicating</span> machines, <span class="tech_translate">stochastic computing</span>), and statistics.<br><br>

                He took Turing’s theory of computers and designed the architecture that would allow the theory to be put into practice. Computers still use the <span class="tech_translate">architecture</span> that he developed in the 1940s. <br><br>

                <img src="img/unit_1/4.jpg" alt="4" class="pic4">
                <span class="people_translate">John Bardeen</span>, <span class="people_translate">William Shockley</span>, and <span class="people_translate">Walter Brattain</span> were engineers at Bell Labs, a research laboratory run by AT&T where many fundamental parts of computers were developed. In 1947, the three invented the <span class="tech_translate">transistor</span>, the <span class="nontech_translate">fundamental</span> building block of modern electronic devices - <span class="nontech_translate">ubiquitous</span> in modern electronic systems. The transistor revolutionized the field of electronics, and <span class="nontech_translate">paved the way</span> for smaller and cheaper radios, calculators, and computers. Before the invention, computers used <span class="tech_translate">vacuum tubes</span> and were the size of a small house. The vacuum tubes would last for only a short time, perhaps 30 minutes, before they burned out and had to be replaced. This <span class="nontech_translate">entailed</span> reprogramming the entire computer – operating system, program, and data.
                <br><br>

                <img src="img/unit_1/steave_jobs.jpg" alt="steve" class="steve">
                <span class="people_translate">Steven Jobs</span>(1955–2011) and <span class="people_translate">Steve Wozniak</span> (1950– ) were American inventors, <span class="nontech_translate">entrepreneurs</span>, and leaders in the personal computer revolution and founded Apple Computer, Inc. <span class="people_translate">Wozniak</span> <span class="nontech_translate">single-handedly</span> developed the 1976 Apple I, which was the computer that launched Apple.<img src="img/unit_1/apple_comp.jpg" alt="apple" class="apple"> He primarily designed the 1977 Apple II, known as one of the first highly successful <span class="nontech_translate">mass-produced</span> microcomputers, while <span class="people_translate">Jobs</span> <span class="nontech_translate">oversaw</span> the development of its unusual case and Rod Holt developed the <span class="nontech_translate">unique</span> power supply. The Apple I was a machine for hobbyists. The design included a <span class="tech_translate">microprocessor</span> on a single <span class="tech_translate">circuit board</span> with 256 bytes of <span class="tech_translate">ROM</span>, 4K or 8K bytes of <span class="tech_translate">RAM</span>, and a 40-character by 24-row display controller. Apple's first computer <span class="nontech_translate">lacked</span> a case, <span class="tech_translate">power supply</span>, keyboard, and display, all <span class="tech_translate">components</span> the user had to provide.<br><br>

                After the success of the Apple I, <span class="people_translate">Wozniak</span> designed the Apple II, the first personal computer that had the ability to display color graphics with built-in <span class="tech_translate tooltip">BASIC</span>.
                <br><br><br>
                <hr>
                </div>
                <div class="sources text"><h3>SOURCES:</h3> <br>

                Hall et al. “CS1300: Introduction to Computing”. Textbook, St. Mary’s University Computer Science Press (2010), San Antonio, Texas.<br><br><br>

                https://en.wikipedia.org/wiki/History_of_computing
                <div>
